# Example configuration file for LLM Council
# Copy this file to .env and fill in your API keys

# OpenRouter (required for most models)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenAI (optional, for direct OpenAI access)
OPENAI_API_KEY=your_openai_api_key_here

# 月之暗面 Moonshot AI (optional)
MOONSHOT_API_KEY=your_moonshot_api_key_here

# DeepSeek (optional)
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# 字节跳动豆包 (optional)
DOUBAO_API_KEY=your_doubao_api_key_here

# Ollama (local models, optional)
OLLAMA_BASE_URL=http://localhost:11434

# Optional: Custom base URLs (only needed if using proxy or alternative endpoints)
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# OPENAI_BASE_URL=https://api.openai.com/v1
# MOONSHOT_BASE_URL=https://api.moonshot.cn/v1
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
# DOUBAO_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

# Backend Configuration
# Note: The following models are configured in data/config.json
# - council_models: List of models that participate in discussions
# - chairman_model: Model that synthesizes the final response
